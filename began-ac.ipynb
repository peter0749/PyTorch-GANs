{"cells":[{"metadata":{"trusted":false,"_uuid":"001b6c90b36d7695119076c079d0d43ee196cf9e"},"cell_type":"code","source":"import os\nimport time\nfrom collections import deque\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport cv2\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"f59bc00a5f443f619d6a28bee655fd28d54a6e87"},"cell_type":"code","source":"if not os.path.exists('./previews'):\n    os.makedirs('./previews')\nif not os.path.exists('./checkpoints'):\n    os.makedirs('./checkpoints')\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nn_class = 10\nn_class_remap = 16\nbatch_size = 64\nn_dim = 32\nn_feature = 128\nn_d_latent = 128\nn_ch = 1\ng_feature_map_b = 64\nd_feature_map_b = 64\n'''\nfold_dataset = datasets.ImageFolder('./cat_b_128/', \n                       transform=transforms.Compose([\n                           transforms.RandomHorizontalFlip(),\n                           transforms.RandomAffine(5, translate=(0.05,0.05), scale=(0.9,1.1), shear=2, resample=2, fillcolor=tuple([127]*n_ch)),\n                           transforms.Resize([n_dim]*2, interpolation=2),\n                           transforms.ToTensor(), # normalize to [0,1]\n                           transforms.Normalize([0.5]*n_ch, [0.5]*n_ch) # [0,1] -> [-1,+1]\n                       ]))\n'''\nfold_dataset = datasets.MNIST('./mnist_data', download=True, train=False, transform=transforms.Compose([\n                           transforms.Pad(2), # 28 -> 32\n                           transforms.ToTensor(), # normalize to [0,1]\n                           transforms.Normalize([0.5]*n_ch, [0.5]*n_ch) # [0,1] -> [-1,+1]\n                       ]))\n\nprint(fold_dataset.__getitem__(100)[0].shape)\nplt.imshow(np.squeeze(np.clip(np.array(fold_dataset.__getitem__(100)[0]).transpose(1,2,0)*127.5+127.5,0,255).astype(np.uint8)))\nplt.show()\ndata_loader = torch.utils.data.DataLoader(\n        fold_dataset,\n        batch_size=batch_size, shuffle=True, num_workers=4)\nprint(n_dim, n_feature)\ndef inf_data_gen():\n    while True:\n        for data, label in data_loader:\n            yield data, label\ngen = inf_data_gen()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"11d244091c83391f529614113a31d9a829201382"},"cell_type":"code","source":"# custom weights initialization called on netG and netD\ndef weights_init(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        nn.init.xavier_normal_(m.weight.data)\n    elif classname.find('Linear') != -1:\n        nn.init.xavier_normal_(m.weight.data)\n\ndef one_hot(ids, n_class):\n    if len(ids.size())==2:\n        return ids\n    ohe = torch.FloatTensor(ids.size(0), n_class)\n    ids = ids.view(-1,1)\n    ohe.zero_()\n    ohe.scatter_(1, ids, 1)\n    return ohe\n\nclass ConvolutioBlock(nn.Module):\n    def __init__(self, in_ch, out_ch, norm=True, down=False, relu=True, leaky=False):\n        super(ConvolutioBlock, self).__init__()\n        \n        conv_block = []\n        conv_block += [nn.Conv2d(in_ch, out_ch, 3, stride=2 if down else 1, padding=1, bias=False)]\n        if norm:\n            conv_block += [nn.InstanceNorm2d(out_ch)]\n        if relu:\n            conv_block += [ nn.LeakyReLU(0.2, inplace=True) if leaky else nn.ReLU(inplace=True) ]\n\n        self.conv_block = nn.Sequential(*conv_block)\n        self.conv_block.apply(weights_init)\n    def forward(self, x):\n        return self.conv_block(x)\n\n# ref SRResNet\nclass ResidualBlock(nn.Module):\n    def __init__(self, in_ch):\n        super(ResidualBlock, self).__init__()\n\n        conv_block = [  nn.Conv2d(in_ch, in_ch, 3, stride=1, padding=1, bias=False),\n                        nn.InstanceNorm2d(in_ch),\n                        nn.ReLU(inplace=True),\n                        nn.Conv2d(in_ch, in_ch, 3, stride=1, padding=1, bias=False),\n                        nn.InstanceNorm2d(in_ch)  \n                     ]\n\n        self.conv_block = nn.Sequential(*conv_block)\n        self.conv_block.apply(weights_init)\n\n    def forward(self, x):\n        return x + self.conv_block(x)\n\nclass UpConvolution(nn.Module):\n    def __init__(self, in_ch, out_ch, norm=True, relu=True, leaky=False):\n        super(UpConvolution, self).__init__()\n        \n        conv_block = [nn.PixelShuffle(2)]\n        conv_block += [nn.Conv2d(in_ch//4, out_ch, 3, stride=1, padding=1, bias=False)]\n        if norm:\n            conv_block += [nn.InstanceNorm2d(out_ch)]\n        if relu:\n            conv_block += [ nn.LeakyReLU(0.2, inplace=True) if leaky else nn.ReLU(inplace=True) ]\n\n        self.conv_block = nn.Sequential(*conv_block)\n        self.conv_block.apply(weights_init)\n\n    def forward(self, x):\n        return self.conv_block(x)\n\nclass C(nn.Module):\n    def __init__(self, N_DIM=32, N_CH=3, BASE_FEATURE_N=32, N_CLASS=1, N_BOTTLENECK=128):\n        super(C, self).__init__()\n        self.n_dim = N_DIM\n        self.n_ch = N_CH\n        self.n_class = N_CLASS\n        self.base_f = BASE_FEATURE_N\n        self.n_bottleneck = N_BOTTLENECK\n        self.head_conv = nn.Conv2d(self.n_ch, self.base_f, 3, stride=1, padding=1, bias=False)\n        weights_init(self.head_conv)\n        self.convs1 = nn.Sequential(*[\n            ConvolutioBlock( self.base_f, self.base_f,   norm=True, down=True, relu=True, leaky=True ), # /2\n            ConvolutioBlock( self.base_f, self.base_f*2, norm=True, down=True, relu=True, leaky=True ), # /4\n            ConvolutioBlock( self.base_f*2, self.base_f*4, norm=True, down=True, relu=True, leaky=True ), # /8\n            ConvolutioBlock( self.base_f*4, self.base_f*8, norm=True, down=True, relu=True, leaky=True ), # /16\n        ])\n        self.fc1 = nn.Linear(self.base_f*8*(self.n_dim//16)**2, self.n_bottleneck, bias=False)\n        self.fc2 = nn.Linear(self.n_bottleneck, self.base_f*8*(self.n_dim//16)**2, bias=False)\n        self.classifier = nn.Linear(self.n_bottleneck, self.n_class, bias=True)\n        weights_init(self.fc1)\n        weights_init(self.fc2)\n        weights_init(self.classifier)\n        self.convs2 = nn.Sequential(*[\n            UpConvolution(self.base_f*8, self.base_f*4, norm=True, relu=True, leaky=True), # 2x\n            UpConvolution(self.base_f*4, self.base_f*2, norm=True, relu=True, leaky=True), # 4x\n            UpConvolution(self.base_f*2, self.base_f, norm=True, relu=True, leaky=True), # 8x\n            UpConvolution(self.base_f, self.base_f, norm=True, relu=True, leaky=True), # 16x\n        ])\n        self.tail_conv = nn.Conv2d(self.base_f, self.n_ch, 3, stride=1, padding=1, bias=False)\n        weights_init(self.tail_conv)\n        \n    def forward(self, x, label):\n        \n        o = x\n        \n        x = self.head_conv(x)\n        x = self.convs1(x)\n        x = x.view(x.size(0), self.base_f*8*(self.n_dim//16)**2)\n        x = self.fc1(x)\n        \n        c = self.classifier(x)\n        bce_loss = nn.functional.cross_entropy(c, label, reduction='mean')\n        \n        x = self.fc2(x)\n        x = x.view(x.size(0), self.base_f*8, self.n_dim//16, self.n_dim//16)\n        x = self.convs2(x)\n        \n        x = self.tail_conv (x)\n        x = torch.tanh(x)\n        return torch.abs(x-o).mean() , bce_loss\n\nclass G(nn.Module):\n    def __init__(self, N_DIM, N_FEATURE, N_CH, BASE_FEATURE_N=32, N_CLASS=1, N_EMB=1):\n        super(G, self).__init__()\n        self.n_dim = N_DIM\n        self.n_ch  = N_CH\n        self.n_class = N_CLASS\n        self.base_f = BASE_FEATURE_N\n        self.n_feature = N_FEATURE\n        self.n_emb = N_EMB\n        self.aux   = nn.Linear(self.n_class, self.n_emb, bias=False)\n        weights_init(self.aux)\n        self.latent_map = nn.Linear(self.n_emb+self.n_feature, self.base_f*8*((self.n_dim//32)**2)) \n        weights_init(self.latent_map)\n        self.convs = nn.Sequential(*[\n            ResidualBlock(self.base_f*8),\n            UpConvolution(self.base_f*8, self.base_f*4, norm=True, relu=True), # 2x\n            UpConvolution(self.base_f*4, self.base_f*4, norm=True, relu=True), # 4x\n            UpConvolution(self.base_f*4, self.base_f*2, norm=True, relu=True), # 8x\n            UpConvolution(self.base_f*2, self.base_f*2, norm=True, relu=True), # 16x\n            UpConvolution(self.base_f*2, self.base_f, norm=True, relu=True),   # 32x\n        ])\n        self.tail_conv = nn.Conv2d(self.base_f, self.n_ch, 3, stride=1, padding=1, bias=False)\n        weights_init(self.tail_conv)\n        \n    def forward(self, x, label):\n        label_emb = self.aux(label)\n        x = torch.cat((x, label_emb), 1)\n        x = self.latent_map(x)\n        x = x.view(x.size(0), self.base_f*8, self.n_dim//32, self.n_dim//32)\n        x = self.convs(x)\n        x = self.tail_conv (x)\n        x = torch.tanh(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"72c9861dd439dc5866601807e118a3e423e11434"},"cell_type":"code","source":"def plot2dir(directory='./previews', imgs=None, iter_n=0):\n    imgs = np.clip(np.round((np.concatenate(tuple(imgs.transpose(0,2,3,1)), axis=0)+1)*127.5), 0, 255).astype(np.uint8) # (?, 28, 28)\n    cv2.imwrite('{}/{:08d}.jpg'.format(directory, iter_n), np.squeeze(imgs[...,::-1])) # RGB->BGR\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"8055a49de3d4c6c40d9add2f416c15d54b346354"},"cell_type":"code","source":"seed = 3 # debug!!!\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\nG_net = G(n_dim, n_feature, n_ch, g_feature_map_b, n_class, n_class_remap).to(device)\nC_net = C(n_dim, n_ch, d_feature_map_b, n_class, n_d_latent).to(device)\nopt_C = optim.Adam(C_net.parameters(), lr=0.0002, betas=(0.5, 0.999))\nopt_G = optim.Adam(G_net.parameters(), lr=0.0002, betas=(0.5, 0.999))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"0e8b40cfb778ca8823cdb19629a57a25bd1f7d0e"},"cell_type":"code","source":"from tqdm import tqdm_notebook\n\niterations = 5000\npreview_iter = 100\n# max_preview_imgs = 5\nd_iter = 1\nstd = 1.0\nmin_k = 0.05\nk = torch.FloatTensor([0]).to(device)\nlambda_k = torch.FloatTensor([0.001]).to(device) \nlambda_c = torch.FloatTensor([0.1]).to(device) \ngamma = torch.FloatTensor([0.75]).to(device) \n\nfor ite in tqdm_notebook(range(1, iterations+1)):\n    start_train_ts = time.time()\n    # train D:\n    G_net.eval()\n    C_net.train()\n    d_loss_mean = []\n    c_loss_mean = []\n    g_loss_mean = 0.0\n    for _ in range(d_iter):\n        opt_C.zero_grad()\n        real, label = next(gen)\n        real = real.to(device)\n        label_ohe = one_hot(label, n_class).to(device)\n        label = label.to(device)\n        sample = torch.randn(real.size(0), n_feature, device=device).clamp(-2,2) * std\n        fake   = G_net(sample, label_ohe).detach() # not to touch G_net\n        d_loss_real, BCE_loss_real = C_net(real, label)\n        BCE_loss_real = lambda_c.detach() * BCE_loss_real\n        d_loss_fake, not_used = C_net(fake, label)\n        d_loss_fake = -k.detach() * d_loss_fake\n        d_loss = d_loss_real + d_loss_fake\n        (d_loss + BCE_loss_real).backward()\n        opt_C.step()\n        d_loss_mean.append(d_loss.item())\n        c_loss_mean.append(BCE_loss_real.item())\n    d_loss_mean = np.mean(d_loss_mean)\n    c_loss_mean = np.mean(c_loss_mean)\n    D_update_ts = time.time()\n    # train G:\n    real, label = next(gen)\n    real = real.to(device)\n    label_ohe = one_hot(label, n_class).to(device)\n    label = label.to(device)\n    G_net.train()\n    C_net.eval()\n    opt_G.zero_grad()\n    opt_C.zero_grad()\n    sample = torch.randn(real.size(0), n_feature, device=device).clamp(-2,2) * std\n    generated = G_net(sample, label_ohe)\n    g_loss, g_bce_loss = C_net(generated, label)\n    g_bce_loss = lambda_c.detach() * g_bce_loss\n    (g_loss + g_bce_loss).backward()\n    opt_G.step()\n    g_loss = g_loss.item()\n    g_bce_loss = g_bce_loss.item()\n    G_update_ts = time.time()\n    k_delta = gamma.detach()*d_loss_real-g_loss\n    M_global = (d_loss_real + torch.abs(k_delta)).item()\n    k = (k + lambda_k.detach()*k_delta).clamp(min=min_k, max=1)\n    if ite%preview_iter==0:\n        print('[{}/{}] G:{:.4f}, D:{:.4f}, C_g:{:4f}, C_d:{:4f}, M:{:4f}, k:{:4f} -- elapsed_G: {:.4f}s -- elapsed_D: {:.4f}s'.format(ite, iterations, g_loss, d_loss_mean, g_bce_loss, c_loss_mean, M_global, k.item(), (G_update_ts-D_update_ts), (D_update_ts-start_train_ts) ))\n        \n        imgs = []\n        for c in range(n_class):\n            sample = torch.randn(1, n_feature, device=device).clamp(-2,2) * std\n            label  = one_hot(torch.LongTensor([c], device=\"cpu\"), n_class).to(device)\n            generated = G_net(sample, label).detach().cpu().numpy()[0]\n            imgs.append(generated)\n        imgs = np.asarray(imgs)\n        \n        plot2dir('./previews', imgs, ite)\n        torch.save(G_net.state_dict(), './checkpoints/iter-{:d}-G.ckpt'.format(ite))\n        torch.save(C_net.state_dict(), './checkpoints/iter-{:d}-D.ckpt'.format(ite))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"535a758cf154c476e58bbe358597061330004db7"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"}},"nbformat":4,"nbformat_minor":1}
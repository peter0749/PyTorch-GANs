{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./previews'):\n",
    "    os.makedirs('./previews')\n",
    "if not os.path.exists('./checkpoints'):\n",
    "    os.makedirs('./checkpoints')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 32\n",
    "n_dim = 128\n",
    "n_feature = 128\n",
    "n_d_latent = 128\n",
    "n_ch = 3\n",
    "g_feature_map_b = 64\n",
    "d_feature_map_b = 64\n",
    "\n",
    "fold_dataset = datasets.ImageFolder('./kaboo', \n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.RandomHorizontalFlip(),\n",
    "                           transforms.RandomAffine(5, translate=(0.05,0.05), scale=(0.9,1.1), shear=2, resample=2, fillcolor=tuple([255]*n_ch)),\n",
    "                           transforms.Resize([n_dim]*2, interpolation=2),\n",
    "                           transforms.ToTensor(), # normalize to [0,1]\n",
    "                           transforms.Normalize([0.5]*n_ch, [0.5]*n_ch) # [0,1] -> [-1,+1]\n",
    "                       ]))\n",
    "'''\n",
    "fold_dataset = datasets.MNIST('./mnist_data', download=True, train=False, transform=transforms.Compose([\n",
    "                           transforms.Pad(2), # 28 -> 32\n",
    "                           transforms.ToTensor(), # normalize to [0,1]\n",
    "                           transforms.Normalize([0.5]*n_ch, [0.5]*n_ch) # [0,1] -> [-1,+1]\n",
    "                       ]))\n",
    "'''\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "        fold_dataset,\n",
    "        batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "def inf_data_gen():\n",
    "    while True:\n",
    "        for data, label in data_loader:\n",
    "            yield data\n",
    "gen = inf_data_gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.xavier_normal_(m.weight.data)\n",
    "    elif classname.find('Linear') != -1:\n",
    "        nn.init.xavier_normal_(m.weight.data)\n",
    "\n",
    "def relaxed_orthogonal_reg(model, device, reg=1e-4):\n",
    "    orth_loss = torch.ones(1, requires_grad=True, device=device)\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'bias' not in name:\n",
    "            param_flat = param.view(param.size(0), -1)\n",
    "            sym = torch.mm(param_flat, torch.t(param_flat))\n",
    "            mask= 1 - torch.eye(param.size(0), device=device)\n",
    "            orth_loss = orth_loss + ((sym*mask)**2).sum()\n",
    "    return reg * orth_loss\n",
    "\n",
    "def one_hot(ids, n_class):\n",
    "    if len(ids.size())==2:\n",
    "        return ids\n",
    "    ohe = torch.FloatTensor(ids.size(0), n_class)\n",
    "    ids = ids.view(-1,1)\n",
    "    ohe.zero_()\n",
    "    ohe.scatter_(1, ids, 1)\n",
    "    return ohe\n",
    "\n",
    "class ConvolutioBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, norm=True, down=False, relu=True, leaky=False):\n",
    "        super(ConvolutioBlock, self).__init__()\n",
    "        \n",
    "        conv_block = []\n",
    "        conv_block += [nn.Conv2d(in_ch, out_ch, 3, stride=2 if down else 1, padding=1, bias=False)]\n",
    "        if norm:\n",
    "            conv_block += [nn.InstanceNorm2d(out_ch)]\n",
    "        if relu:\n",
    "            conv_block += [ nn.LeakyReLU(0.2, inplace=True) if leaky else nn.ReLU(inplace=True) ]\n",
    "\n",
    "        self.conv_block = nn.Sequential(*conv_block)\n",
    "        self.conv_block.apply(weights_init)\n",
    "    def forward(self, x):\n",
    "        return self.conv_block(x)\n",
    "\n",
    "# ref SRResNet\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_ch):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        conv_block = [  nn.Conv2d(in_ch, in_ch, 3, stride=1, padding=1, bias=False),\n",
    "                        nn.InstanceNorm2d(in_ch),\n",
    "                        nn.ReLU(inplace=True),\n",
    "                        nn.Conv2d(in_ch, in_ch, 3, stride=1, padding=1, bias=False),\n",
    "                        nn.InstanceNorm2d(in_ch)  \n",
    "                     ]\n",
    "\n",
    "        self.conv_block = nn.Sequential(*conv_block)\n",
    "        self.conv_block.apply(weights_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.conv_block(x)\n",
    "\n",
    "class UpConvolution(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, norm=True, relu=True, leaky=False):\n",
    "        super(UpConvolution, self).__init__()\n",
    "        \n",
    "        conv_block = [nn.PixelShuffle(2)]\n",
    "        conv_block += [nn.Conv2d(in_ch//4, out_ch, 3, stride=1, padding=1, bias=False)]\n",
    "        if norm:\n",
    "            conv_block += [nn.InstanceNorm2d(out_ch)]\n",
    "        if relu:\n",
    "            conv_block += [ nn.LeakyReLU(0.2, inplace=True) if leaky else nn.ReLU(inplace=True) ]\n",
    "\n",
    "        self.conv_block = nn.Sequential(*conv_block)\n",
    "        self.conv_block.apply(weights_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv_block(x)\n",
    "\n",
    "class C(nn.Module):\n",
    "    def __init__(self, N_DIM=32, N_CH=3, BASE_FEATURE_N=32, N_BOTTLENECK=128):\n",
    "        super(C, self).__init__()\n",
    "        self.n_dim = N_DIM\n",
    "        self.n_ch = N_CH\n",
    "        self.base_f = BASE_FEATURE_N\n",
    "        self.n_bottleneck = N_BOTTLENECK\n",
    "        self.head_conv = nn.Conv2d(self.n_ch, self.base_f, 3, stride=1, padding=1, bias=False)\n",
    "        weights_init(self.head_conv)\n",
    "        self.convs1 = nn.Sequential(*[\n",
    "            ConvolutioBlock( self.base_f, self.base_f,   norm=True, down=True, relu=True, leaky=True ), # /2\n",
    "            ConvolutioBlock( self.base_f, self.base_f*2, norm=True, down=True, relu=True, leaky=True ), # /4\n",
    "            ConvolutioBlock( self.base_f*2, self.base_f*4, norm=True, down=True, relu=True, leaky=True ), # /8\n",
    "            ConvolutioBlock( self.base_f*4, self.base_f*8, norm=True, down=True, relu=True, leaky=True ), # /16\n",
    "            ConvolutioBlock( self.base_f*8, self.base_f*8, norm=True, down=True, relu=True, leaky=True ), # /32\n",
    "        ])\n",
    "        self.fc1 = nn.Linear(self.base_f*8*(self.n_dim//32)**2, self.n_bottleneck, bias=False)\n",
    "        self.fc2 = nn.Linear(self.n_bottleneck, self.base_f*8*(self.n_dim//32)**2, bias=False)\n",
    "        weights_init(self.fc1)\n",
    "        weights_init(self.fc2)\n",
    "        self.convs2 = nn.Sequential(*[\n",
    "            UpConvolution(self.base_f*8, self.base_f*8, norm=True, relu=True, leaky=True), # 2x\n",
    "            UpConvolution(self.base_f*8, self.base_f*4, norm=True, relu=True, leaky=True), # 4x\n",
    "            UpConvolution(self.base_f*4, self.base_f*2, norm=True, relu=True, leaky=True), # 8x\n",
    "            UpConvolution(self.base_f*2, self.base_f, norm=True, relu=True, leaky=True), # 16x\n",
    "            UpConvolution(self.base_f, self.base_f, norm=True, relu=True, leaky=True), # 32x\n",
    "        ])\n",
    "        self.tail_conv = nn.Conv2d(self.base_f, self.n_ch, 3, stride=1, padding=1, bias=False)\n",
    "        weights_init(self.tail_conv)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        o = x\n",
    "        \n",
    "        x = self.head_conv(x)\n",
    "        x = self.convs1(x)\n",
    "        x = x.view(x.size(0), self.base_f*8*(self.n_dim//32)**2)\n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = x.view(x.size(0), self.base_f*8, self.n_dim//32, self.n_dim//32)\n",
    "        x = self.convs2(x)\n",
    "        \n",
    "        x = self.tail_conv (x)\n",
    "        x = torch.tanh(x)\n",
    "        return torch.abs(x-o).mean()\n",
    "\n",
    "class G(nn.Module):\n",
    "    def __init__(self, N_DIM, N_FEATURE, N_CH, BASE_FEATURE_N=32):\n",
    "        super(G, self).__init__()\n",
    "        self.n_dim = N_DIM\n",
    "        self.n_ch  = N_CH\n",
    "        self.base_f = BASE_FEATURE_N\n",
    "        self.n_feature = N_FEATURE\n",
    "        self.latent_map = nn.Linear(self.n_feature, self.base_f*8*((self.n_dim//32)**2)) \n",
    "        weights_init(self.latent_map)\n",
    "        self.convs = nn.Sequential(*[\n",
    "            ResidualBlock(self.base_f*8),\n",
    "            UpConvolution(self.base_f*8, self.base_f*8, norm=True, relu=True, leaky=True), # 2x\n",
    "            UpConvolution(self.base_f*8, self.base_f*4, norm=True, relu=True, leaky=True), # 4x\n",
    "            UpConvolution(self.base_f*4, self.base_f*2, norm=True, relu=True, leaky=True), # 8x\n",
    "            UpConvolution(self.base_f*2, self.base_f, norm=True, relu=True, leaky=True),   # 16x\n",
    "            UpConvolution(self.base_f,   self.base_f, norm=True, relu=True, leaky=True),   # 32x\n",
    "        ])\n",
    "        self.tail_conv = nn.Conv2d(self.base_f, self.n_ch, 3, stride=1, padding=1, bias=False)\n",
    "        weights_init(self.tail_conv)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.latent_map(x)\n",
    "        x = x.view(x.size(0), self.base_f*8, self.n_dim//32, self.n_dim//32)\n",
    "        x = self.convs(x)\n",
    "        x = self.tail_conv (x)\n",
    "        x = torch.tanh(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot2dir(directory='./previews', imgs=None, iter_n=0):\n",
    "    imgs = np.clip(np.round((np.concatenate(tuple(imgs.transpose(0,2,3,1)), axis=0)+1)*127.5), 0, 255).astype(np.uint8) # (?, 28, 28)\n",
    "    cv2.imwrite('{}/{:08d}.jpg'.format(directory, iter_n), np.squeeze(imgs[...,::-1])) # RGB->BGR\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_net = G(n_dim, n_feature, n_ch, g_feature_map_b).to(device)\n",
    "C_net = C(n_dim, n_ch, d_feature_map_b, n_d_latent).to(device)\n",
    "opt_C = optim.Adam(C_net.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "opt_G = optim.Adam(G_net.parameters(), lr=0.0002, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d84288941017463ebac7d7281802fa8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=50000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200/50000] G:0.0440, D:0.1284, M:0.1494, k:0.0064 -- elapsed_G: 0.17s -- elapsed_D: 0.22s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-443121d53225>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0md_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mopt_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0md_loss_mean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0md_loss_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_loss_mean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mD_update_ts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "\n",
    "iterations = 50000\n",
    "preview_iter = 200\n",
    "preview_imgs = 8\n",
    "d_iter = 1\n",
    "std = 1.0\n",
    "min_k = 0.001\n",
    "k = torch.FloatTensor([0]).to(device)\n",
    "lambda_k = torch.FloatTensor([0.001]).to(device) \n",
    "gamma = torch.FloatTensor([0.75]).to(device) \n",
    "\n",
    "samples_preview = []\n",
    "for c in range(preview_imgs):\n",
    "    samples_preview.append(torch.randn(preview_imgs, n_feature).clamp(-3,3) * std)\n",
    "\n",
    "for ite in tqdm_notebook(range(1, iterations+1)):\n",
    "    start_train_ts = time.time()\n",
    "    # train D:\n",
    "    G_net.eval()\n",
    "    C_net.train()\n",
    "    d_loss_mean = []\n",
    "    g_loss_mean = 0.0\n",
    "    for _ in range(d_iter):\n",
    "        real = next(gen)\n",
    "        real = real.to(device)\n",
    "        sample = torch.randn(real.size(0), n_feature, device=device).clamp(-3,3) * std\n",
    "        fake   = G_net(sample).detach() # not to touch G_net\n",
    "        d_loss_real = C_net(real)\n",
    "        d_loss_fake = C_net(fake)\n",
    "        d_loss_fake = -k.detach() * d_loss_fake\n",
    "        d_loss = d_loss_real + d_loss_fake + relaxed_orthogonal_reg(C_net, device)\n",
    "        opt_C.zero_grad()\n",
    "        d_loss.backward()\n",
    "        opt_C.step()\n",
    "        d_loss_mean.append(d_loss.item())\n",
    "    d_loss_mean = np.mean(d_loss_mean)\n",
    "    D_update_ts = time.time()\n",
    "    # train G:\n",
    "    real = next(gen)\n",
    "    real = real.to(device)\n",
    "    G_net.train()\n",
    "    C_net.eval()\n",
    "    sample = torch.randn(real.size(0), n_feature, device=device).clamp(-3,3) * std\n",
    "    generated = G_net(sample)\n",
    "    g_loss = C_net(generated) + relaxed_orthogonal_reg(G_net, device)\n",
    "    opt_G.zero_grad()\n",
    "    opt_C.zero_grad()\n",
    "    g_loss.backward()\n",
    "    opt_G.step()\n",
    "    g_loss = g_loss.item()\n",
    "    G_update_ts = time.time()\n",
    "    k_delta = gamma.detach()*d_loss_real-g_loss\n",
    "    M_global = (d_loss_real + torch.abs(k_delta)).item()\n",
    "    k = (k + lambda_k.detach()*k_delta).clamp(min=min_k, max=1)\n",
    "    if ite%preview_iter==0:\n",
    "        print('[{}/{}] G:{:.4f}, D:{:.4f}, M:{:.4f}, k:{:.4f} -- elapsed_G: {:.2f}s -- elapsed_D: {:.2f}s'.format(ite, iterations, g_loss, d_loss_mean, M_global, k.item(), (G_update_ts-D_update_ts), (D_update_ts-start_train_ts) ))\n",
    "        \n",
    "        imgs = []\n",
    "        for sample in samples_preview:\n",
    "            generated = G_net(sample.to(device)).detach().cpu().numpy()\n",
    "            imgs.append(np.concatenate(generated, axis=2))\n",
    "        imgs = np.asarray(imgs)\n",
    "        \n",
    "        plot2dir('./previews', imgs, ite)\n",
    "        torch.save(G_net.state_dict(), './checkpoints/iter-{:d}-G.ckpt'.format(ite))\n",
    "        torch.save(C_net.state_dict(), './checkpoints/iter-{:d}-D.ckpt'.format(ite))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

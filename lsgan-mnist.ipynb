{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 32])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 100\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('./previews'):\n",
    "    os.makedirs('./previews')\n",
    "if not os.path.exists('./checkpoints'):\n",
    "    os.makedirs('./checkpoints')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 32\n",
    "n_dim = 32\n",
    "n_feature = 100\n",
    "n_ch = 1\n",
    "g_feature_map_b = 64\n",
    "d_feature_map_b = 64\n",
    "'''\n",
    "fold_dataset = datasets.ImageFolder('./pixiv_face_tagged', \n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.RandomHorizontalFlip(),\n",
    "                           transforms.RandomAffine(5, translate=(0.05,0.05), scale=(0.9,1.1), shear=2, resample=2, fillcolor=tuple([127]*n_ch)),\n",
    "                           transforms.Resize([n_dim]*2, interpolation=2),\n",
    "                           transforms.ToTensor(), # normalize to [0,1]\n",
    "                           transforms.Normalize([0.5]*n_ch, [0.5]*n_ch) # [0,1] -> [-1,+1]\n",
    "                       ]))\n",
    "'''\n",
    "fold_dataset = datasets.MNIST('./mnist_data', download=True, train=False, transform=transforms.Compose([\n",
    "                           transforms.Pad(2), # 28 -> 32\n",
    "                           transforms.ToTensor(), # normalize to [0,1]\n",
    "                           transforms.Normalize([0.5]*n_ch, [0.5]*n_ch) # [0,1] -> [-1,+1]\n",
    "                       ]))\n",
    "\n",
    "print(fold_dataset.__getitem__(100)[0].shape)\n",
    "plt.imshow(np.squeeze(np.clip(np.array(fold_dataset.__getitem__(100)[0]).transpose(1,2,0)*127.5+127.5,0,255).astype(np.uint8)))\n",
    "plt.show()\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "        fold_dataset,\n",
    "        batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "print(n_dim, n_feature)\n",
    "def inf_data_gen():\n",
    "    while True:\n",
    "        for data, label in data_loader:\n",
    "            yield data\n",
    "gen = inf_data_gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.xavier_normal_(m.weight.data)\n",
    "    elif classname.find('Linear') != -1:\n",
    "        nn.init.xavier_normal_(m.weight.data)\n",
    "\n",
    "def one_hot(ids, n_class):\n",
    "    if len(ids.size())==2:\n",
    "        return ids\n",
    "    ohe = torch.FloatTensor(ids.size(0), n_class)\n",
    "    ids = ids.view(-1,1)\n",
    "    ohe.zero_()\n",
    "    ohe.scatter_(1, ids, 1)\n",
    "    return ohe\n",
    "\n",
    "class ConvolutioBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, norm=True, down=False, relu=True, leaky=False, dropout=False):\n",
    "        super(ConvolutioBlock, self).__init__()\n",
    "        \n",
    "        conv_block = []\n",
    "        conv_block += [nn.Conv2d(in_ch, out_ch, 3, stride=2 if down else 1, padding=1, bias=False)]\n",
    "        if norm:\n",
    "            conv_block += [nn.InstanceNorm2d(out_ch)]\n",
    "        if relu:\n",
    "            conv_block += [ nn.LeakyReLU(0.2, inplace=True) if leaky else nn.ReLU(inplace=True) ]\n",
    "        if dropout:\n",
    "            conv_block += [nn.Dropout(0.05)]\n",
    "\n",
    "        self.conv_block = nn.Sequential(*conv_block)\n",
    "        self.conv_block.apply(weights_init)\n",
    "    def forward(self, x):\n",
    "        return self.conv_block(x)\n",
    "\n",
    "# ref SRResNet\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_ch):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        conv_block = [  nn.Conv2d(in_ch, in_ch, 3, stride=1, padding=1, bias=False),\n",
    "                        nn.InstanceNorm2d(in_ch),\n",
    "                        nn.ReLU(inplace=True),\n",
    "                        nn.Conv2d(in_ch, in_ch, 3, stride=1, padding=1, bias=False),\n",
    "                        nn.InstanceNorm2d(in_ch)  \n",
    "                     ]\n",
    "\n",
    "        self.conv_block = nn.Sequential(*conv_block)\n",
    "        self.conv_block.apply(weights_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.conv_block(x)\n",
    "\n",
    "class UpConvolution(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, norm=True, relu=True):\n",
    "        super(UpConvolution, self).__init__()\n",
    "        \n",
    "        conv_block = [nn.PixelShuffle(2)]\n",
    "        conv_block += [nn.Conv2d(in_ch//4, out_ch, 3, stride=1, padding=1, bias=False)]\n",
    "        if norm:\n",
    "            conv_block += [nn.InstanceNorm2d(out_ch)]\n",
    "        if relu:\n",
    "            conv_block += [nn.ReLU(inplace=True)]\n",
    "\n",
    "        self.conv_block = nn.Sequential(*conv_block)\n",
    "        self.conv_block.apply(weights_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv_block(x)\n",
    "\n",
    "class C(nn.Module):\n",
    "    def __init__(self, N_DIM=32, N_CH=3, BASE_FEATURE_N=32):\n",
    "        super(C, self).__init__()\n",
    "        self.n_dim = N_DIM\n",
    "        self.n_ch = N_CH\n",
    "        self.base_f = BASE_FEATURE_N\n",
    "        self.head_conv = nn.Conv2d(self.n_ch, self.base_f, 3, stride=1, padding=1, bias=False)\n",
    "        weights_init(self.head_conv)\n",
    "        self.convs = nn.Sequential(*[\n",
    "            ConvolutioBlock( self.base_f, self.base_f,   norm=True, down=True, relu=True, leaky=True, dropout=True ),\n",
    "            ConvolutioBlock( self.base_f, self.base_f*2, norm=True, down=True, relu=True, leaky=True, dropout=True ),\n",
    "            ConvolutioBlock( self.base_f*2, self.base_f*4, norm=True, down=True, relu=True, leaky=True, dropout=True ),\n",
    "            ConvolutioBlock( self.base_f*4, self.base_f*8, norm=True, down=True, relu=True, leaky=True, dropout=True ),\n",
    "        ])\n",
    "        self.tail_conv = nn.Conv2d(self.base_f*8, 1, self.n_dim//16, stride=1, padding=0, bias=False)\n",
    "        weights_init(self.tail_conv)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.head_conv(x)\n",
    "        \n",
    "        x = self.convs(x)\n",
    "        \n",
    "        x = self.tail_conv (x)\n",
    "        x = x.view(x.size(0), 1) \n",
    "        return x\n",
    "\n",
    "class G(nn.Module):\n",
    "    def __init__(self, N_DIM, N_FEATURE, N_CH, BASE_FEATURE_N=32):\n",
    "        super(G, self).__init__()\n",
    "        self.n_dim = N_DIM\n",
    "        self.n_ch  = N_CH\n",
    "        self.base_f = BASE_FEATURE_N\n",
    "        self.n_feature = N_FEATURE\n",
    "        self.latent_map = nn.Linear(self.n_feature, self.base_f*8*((self.n_dim//32)**2)) \n",
    "        weights_init(self.latent_map)\n",
    "        self.convs = nn.Sequential(*[\n",
    "            ResidualBlock(self.base_f*8),\n",
    "            UpConvolution(self.base_f*8, self.base_f*4, norm=True, relu=True), # 2x\n",
    "            UpConvolution(self.base_f*4, self.base_f*4, norm=True, relu=True), # 4x\n",
    "            UpConvolution(self.base_f*4, self.base_f*2, norm=True, relu=True), # 8x\n",
    "            UpConvolution(self.base_f*2, self.base_f*2, norm=True, relu=True), # 16x\n",
    "            UpConvolution(self.base_f*2, self.base_f, norm=True, relu=True),   # 32x\n",
    "        ])\n",
    "        self.tail_conv = nn.Conv2d(self.base_f, self.n_ch, 3, stride=1, padding=1, bias=False)\n",
    "        weights_init(self.tail_conv)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.latent_map(x)\n",
    "        x = x.view(x.size(0), self.base_f*8, self.n_dim//32, self.n_dim//32)\n",
    "        x = self.convs(x)\n",
    "        x = self.tail_conv (x)\n",
    "        x = torch.tanh(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot2dir(directory='./previews', imgs=None, iter_n=0):\n",
    "    imgs = np.clip(np.round((np.concatenate(tuple(imgs.transpose(0,2,3,1)), axis=0)+1)*127.5), 0, 255).astype(np.uint8) # (?, 28, 28)\n",
    "    cv2.imwrite('{}/{:08d}.jpg'.format(directory, iter_n), np.squeeze(imgs[...,::-1])) # RGB->BGR\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 3 # debug!!!\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "G_net = G(n_dim, n_feature, n_ch, g_feature_map_b).to(device)\n",
    "C_net = C(n_dim, n_ch, d_feature_map_b).to(device)\n",
    "opt_C = optim.Adam(C_net.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "opt_G = optim.Adam(G_net.parameters(), lr=0.0002, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47c9811fef624a7992d3f2de88117b40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200/5000] G: 0.3411, D:0.1295 -- elapsed_G: 0.0324s -- elapsed_D: 0.0200s\n",
      "[400/5000] G: 0.4068, D:0.1421 -- elapsed_G: 0.0322s -- elapsed_D: 0.0208s\n",
      "[600/5000] G: 0.3112, D:0.1091 -- elapsed_G: 0.0327s -- elapsed_D: 0.0205s\n",
      "[800/5000] G: 0.4945, D:0.0998 -- elapsed_G: 0.0322s -- elapsed_D: 0.0207s\n",
      "[1000/5000] G: 0.4056, D:0.1638 -- elapsed_G: 0.0324s -- elapsed_D: 0.0208s\n",
      "[1200/5000] G: 0.4485, D:0.1403 -- elapsed_G: 0.0323s -- elapsed_D: 0.0207s\n",
      "[1400/5000] G: 0.6412, D:0.1034 -- elapsed_G: 0.0346s -- elapsed_D: 0.0232s\n",
      "[1600/5000] G: 0.3921, D:0.0960 -- elapsed_G: 0.0328s -- elapsed_D: 0.0229s\n",
      "[1800/5000] G: 0.1384, D:0.1578 -- elapsed_G: 0.0322s -- elapsed_D: 0.0200s\n",
      "[2000/5000] G: 0.6310, D:0.1164 -- elapsed_G: 0.0320s -- elapsed_D: 0.0202s\n",
      "[2200/5000] G: 0.3154, D:0.1459 -- elapsed_G: 0.0323s -- elapsed_D: 0.0203s\n",
      "[2400/5000] G: 0.3951, D:0.1514 -- elapsed_G: 0.0324s -- elapsed_D: 0.0207s\n",
      "[2600/5000] G: 0.4499, D:0.1274 -- elapsed_G: 0.0330s -- elapsed_D: 0.0210s\n",
      "[2800/5000] G: 0.3671, D:0.1875 -- elapsed_G: 0.0324s -- elapsed_D: 0.0201s\n",
      "[3000/5000] G: 0.4221, D:0.2032 -- elapsed_G: 0.0331s -- elapsed_D: 0.0205s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6fc9411e4fd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mg_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mopt_G\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mg_loss_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0mG_update_ts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mite\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mpreview_iter\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "\n",
    "iterations = 5000\n",
    "preview_iter = 200\n",
    "preview_imgs = 8\n",
    "d_iter = 1\n",
    "std = 1.0\n",
    "lambda_1 , lambda_2 = 10 , 0.2\n",
    "M = 0.05\n",
    "\n",
    "samples_preview = []\n",
    "for c in range(preview_imgs):\n",
    "    samples_preview.append(torch.randn(preview_imgs, n_feature).clamp(-3,3) * std)\n",
    "\n",
    "for ite in tqdm_notebook(range(1, iterations+1)):\n",
    "    start_train_ts = time.time()\n",
    "    # train D:\n",
    "    G_net.eval()\n",
    "    C_net.train()\n",
    "    d_loss_mean = 0.0\n",
    "    g_loss_mean = 0.0\n",
    "    for _ in range(d_iter):\n",
    "        opt_C.zero_grad()\n",
    "        real = next(gen).to(device)\n",
    "        sample = torch.randn(real.size(0), n_feature, device=device).clamp(-3,3) * std\n",
    "        fake   = G_net(sample).detach() # not to touch G_net\n",
    "        d_loss_real = 0.5 * ((C_net(real)-1)**2).mean()\n",
    "        d_loss_real.backward()\n",
    "        d_loss_fake = 0.5 * ((C_net(fake)  )**2).mean()\n",
    "        d_loss_fake.backward()\n",
    "        d_loss = d_loss_real + d_loss_fake # + d_loss_gp\n",
    "        opt_C.step()\n",
    "        d_loss_mean += d_loss.item()\n",
    "    d_loss_mean /= d_iter\n",
    "    D_update_ts = time.time()\n",
    "    # train G:\n",
    "    real = next(gen).to(device)\n",
    "    G_net.train()\n",
    "    C_net.train() # activate Discriminator's Dropout \n",
    "    opt_G.zero_grad()\n",
    "    sample = torch.randn(real.size(0), n_feature, device=device).clamp(-3,3) * std\n",
    "    generated = G_net(sample)\n",
    "    g_loss = 0.5 * ((C_net(generated)-1)**2).mean()\n",
    "    g_loss.backward()\n",
    "    opt_G.step()\n",
    "    g_loss_mean = g_loss.mean().item()\n",
    "    G_update_ts = time.time()\n",
    "    if ite%preview_iter==0:\n",
    "        print('[{}/{}] G: {:.4f}, D:{:.4f} -- elapsed_G: {:.4f}s -- elapsed_D: {:.4f}s'.format(ite, iterations, g_loss_mean, d_loss_mean, (G_update_ts-D_update_ts), (D_update_ts-start_train_ts) ))\n",
    "        \n",
    "        G_net.eval() # evaluation state\n",
    "        imgs = []\n",
    "        for sample in samples_preview:\n",
    "            generated = G_net(sample.to(device)).detach().cpu().numpy()\n",
    "            imgs.append(np.concatenate(generated, axis=2))\n",
    "        imgs = np.asarray(imgs)\n",
    "        \n",
    "        plot2dir('./previews', imgs, ite)\n",
    "        torch.save(G_net.state_dict(), './checkpoints/iter-{:d}-G.ckpt'.format(ite))\n",
    "        torch.save(C_net.state_dict(), './checkpoints/iter-{:d}-D.ckpt'.format(ite))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

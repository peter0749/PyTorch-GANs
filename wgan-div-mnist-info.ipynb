{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 32])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 100\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('./previews'):\n",
    "    os.makedirs('./previews')\n",
    "if not os.path.exists('./checkpoints'):\n",
    "    os.makedirs('./checkpoints')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 32\n",
    "n_class = 10\n",
    "n_continue = 32\n",
    "n_hidden = 32\n",
    "n_dim = 32\n",
    "n_feature = 100\n",
    "n_ch = 1\n",
    "g_feature_map_b = 64\n",
    "d_feature_map_b = 64\n",
    "'''\n",
    "fold_dataset = datasets.ImageFolder('./pixiv_face_tagged', \n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.RandomHorizontalFlip(),\n",
    "                           transforms.RandomAffine(5, translate=(0.05,0.05), scale=(0.9,1.1), shear=2, resample=2, fillcolor=tuple([127]*n_ch)),\n",
    "                           transforms.Resize([n_dim]*2, interpolation=2),\n",
    "                           transforms.ToTensor(), # normalize to [0,1]\n",
    "                           transforms.Normalize([0.5]*n_ch, [0.5]*n_ch) # [0,1] -> [-1,+1]\n",
    "                       ]))\n",
    "'''\n",
    "fold_dataset = datasets.MNIST('./mnist_data', download=True, train=False, transform=transforms.Compose([\n",
    "                           transforms.Pad(2), # 28 -> 32\n",
    "                           transforms.ToTensor(), # normalize to [0,1]\n",
    "                           transforms.Normalize([0.5]*n_ch, [0.5]*n_ch) # [0,1] -> [-1,+1]\n",
    "                       ]))\n",
    "\n",
    "print(fold_dataset.__getitem__(100)[0].shape)\n",
    "plt.imshow(np.squeeze(np.clip(np.array(fold_dataset.__getitem__(100)[0]).transpose(1,2,0)*127.5+127.5,0,255).astype(np.uint8)))\n",
    "plt.show()\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "        fold_dataset,\n",
    "        batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "print(n_dim, n_feature)\n",
    "def inf_data_gen():\n",
    "    while True:\n",
    "        for data, label in data_loader:\n",
    "            yield data\n",
    "gen = inf_data_gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0, 0.001)\n",
    "    elif classname.find('Linear') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0, 0.001)\n",
    "\n",
    "def one_hot(ids, n_class):\n",
    "    if len(ids.size())==2:\n",
    "        return ids\n",
    "    ohe = torch.FloatTensor(ids.size(0), n_class)\n",
    "    ids = ids.view(-1,1)\n",
    "    ohe.zero_()\n",
    "    ohe.scatter_(1, ids, 1)\n",
    "    return ohe\n",
    "\n",
    "def wgan_div_gp(real, d_real, device, p):\n",
    "    ones_real = torch.ones_like(d_real, device=device, requires_grad=False)\n",
    "    gradients_real = torch.autograd.grad(\n",
    "            outputs=d_real,\n",
    "            inputs=real,\n",
    "            grad_outputs=ones_real,\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "            only_inputs=True,\n",
    "        )[0]\n",
    "    return gradients_real.view(gradients_real.size(0),-1).pow(2).sum(1)**(p/2) \n",
    "\n",
    "class ConvolutioBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, norm=True, down=False, relu=True, leaky=False, dropout=False):\n",
    "        super(ConvolutioBlock, self).__init__()\n",
    "        \n",
    "        conv_block = []\n",
    "        conv_block += [nn.Conv2d(in_ch, out_ch, 3, stride=2 if down else 1, padding=1, bias=False)]\n",
    "        if norm:\n",
    "            conv_block += [nn.InstanceNorm2d(out_ch)]\n",
    "        if relu:\n",
    "            conv_block += [ nn.LeakyReLU(0.2, inplace=True) if leaky else nn.ReLU(inplace=True) ]\n",
    "        if dropout:\n",
    "            conv_block += [nn.Dropout(0.05)]\n",
    "\n",
    "        self.conv_block = nn.Sequential(*conv_block)\n",
    "        self.conv_block.apply(weights_init)\n",
    "    def forward(self, x):\n",
    "        return self.conv_block(x)\n",
    "\n",
    "# ref SRResNet\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_ch):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        conv_block = [  nn.Conv2d(in_ch, in_ch, 3, stride=1, padding=1, bias=False),\n",
    "                        nn.InstanceNorm2d(in_ch),\n",
    "                        nn.ReLU(inplace=True),\n",
    "                        nn.Conv2d(in_ch, in_ch, 3, stride=1, padding=1, bias=False),\n",
    "                        nn.InstanceNorm2d(in_ch)  \n",
    "                     ]\n",
    "\n",
    "        self.conv_block = nn.Sequential(*conv_block)\n",
    "        self.conv_block.apply(weights_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.conv_block(x)\n",
    "\n",
    "class UpConvolution(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, norm=True, relu=True):\n",
    "        super(UpConvolution, self).__init__()\n",
    "        \n",
    "        conv_block = [nn.PixelShuffle(2)]\n",
    "        conv_block += [nn.Conv2d(in_ch//4, out_ch, 3, stride=1, padding=1, bias=False)]\n",
    "        if norm:\n",
    "            conv_block += [nn.InstanceNorm2d(out_ch)]\n",
    "        if relu:\n",
    "            conv_block += [nn.ReLU(inplace=True)]\n",
    "\n",
    "        self.conv_block = nn.Sequential(*conv_block)\n",
    "        self.conv_block.apply(weights_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv_block(x)\n",
    "\n",
    "class C(nn.Module):\n",
    "    def __init__(self, N_DIM=32, N_CH=3, BASE_FEATURE_N=32, N_CLASS=1, N_CONTINUE=1, N_HIDDEN=1):\n",
    "        super(C, self).__init__()\n",
    "        self.n_class = N_CLASS\n",
    "        self.n_continue = N_CONTINUE\n",
    "        self.n_hidden = N_HIDDEN\n",
    "        self.n_dim = N_DIM\n",
    "        self.n_ch = N_CH\n",
    "        self.base_f = BASE_FEATURE_N\n",
    "        self.head_conv = nn.Conv2d(self.n_ch, self.base_f, 3, stride=1, padding=1, bias=False)\n",
    "        weights_init(self.head_conv)\n",
    "        self.convs = nn.Sequential(*[\n",
    "            ConvolutioBlock( self.base_f, self.base_f,   norm=True, down=True, relu=True, leaky=True, dropout=True ),\n",
    "            ConvolutioBlock( self.base_f, self.base_f*2, norm=True, down=True, relu=True, leaky=True, dropout=True ),\n",
    "            ConvolutioBlock( self.base_f*2, self.base_f*4, norm=True, down=True, relu=True, leaky=True, dropout=True ),\n",
    "            #ConvolutioBlock( self.base_f*4, self.base_f*8, norm=True, down=True, relu=True, leaky=True, dropout=True ),\n",
    "        ])\n",
    "        self.hidden = nn.Linear(self.base_f*4*(self.n_dim//8)**2, self.n_hidden, bias=False)\n",
    "        weights_init(self.hidden)\n",
    "        self.fc_class = nn.Linear(self.n_hidden, self.n_class, bias=False)\n",
    "        weights_init(self.fc_class)\n",
    "        self.fc_continue = nn.Linear(self.n_hidden, self.n_continue, bias=False)\n",
    "        weights_init(self.fc_continue)\n",
    "        self.fc_adv = nn.Linear(self.n_hidden, 1, bias=False)\n",
    "        weights_init(self.fc_adv)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.head_conv(x)\n",
    "        x = self.convs(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.hidden(x)\n",
    "        adv = self.fc_adv(x)\n",
    "        c = F.log_softmax(self.fc_class(x), dim=1)\n",
    "        cnt = self.fc_continue(x)\n",
    "        return adv, c, cnt\n",
    "\n",
    "class G(nn.Module):\n",
    "    def __init__(self, N_DIM, N_FEATURE, N_CH, BASE_FEATURE_N=32, N_CLASS=1, N_CONTINUE=1, N_EMB=1):\n",
    "        super(G, self).__init__()\n",
    "        self.n_emb = N_EMB\n",
    "        self.n_class = N_CLASS\n",
    "        self.n_continue = N_CONTINUE\n",
    "        self.n_dim = N_DIM\n",
    "        self.n_ch  = N_CH\n",
    "        self.base_f = BASE_FEATURE_N\n",
    "        self.n_feature = N_FEATURE\n",
    "        self.aux   = nn.Linear(self.n_class, self.n_emb, bias=False)\n",
    "        weights_init(self.aux)\n",
    "        self.latent_map = nn.Linear(self.n_emb+self.n_feature+self.n_continue, self.base_f*8*((self.n_dim//16)**2)) \n",
    "        weights_init(self.latent_map)\n",
    "        self.convs = nn.Sequential(*[\n",
    "            UpConvolution(self.base_f*8, self.base_f*4, norm=True, relu=True), # 2x\n",
    "            UpConvolution(self.base_f*4, self.base_f*2, norm=True, relu=True), # 8x\n",
    "            UpConvolution(self.base_f*2, self.base_f*2, norm=True, relu=True), # 16x\n",
    "            UpConvolution(self.base_f*2, self.base_f, norm=True, relu=True),   # 32x\n",
    "        ])\n",
    "        self.tail_conv = nn.Conv2d(self.base_f, self.n_ch, 3, stride=1, padding=1, bias=False)\n",
    "        weights_init(self.tail_conv)\n",
    "        \n",
    "    def forward(self, x, label, cnt):\n",
    "        label_emb = self.aux(label)\n",
    "        x = torch.cat((x, label_emb, cnt), 1)\n",
    "        x = self.latent_map(x)\n",
    "        x = x.view(x.size(0), self.base_f*8, self.n_dim//16, self.n_dim//16)\n",
    "        x = self.convs(x)\n",
    "        x = self.tail_conv (x)\n",
    "        x = torch.tanh(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot2dir(directory='./previews', imgs=None, iter_n=0):\n",
    "    imgs = np.clip(np.round((np.concatenate(tuple(imgs.transpose(0,2,3,1)), axis=0)+1)*127.5), 0, 255).astype(np.uint8) # (?, 28, 28)\n",
    "    cv2.imwrite('{}/{:08d}.jpg'.format(directory, iter_n), np.squeeze(imgs[...,::-1])) # RGB->BGR\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 3 # debug!!!\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "G_net = G(n_dim, n_feature, n_ch, g_feature_map_b, n_class, n_continue, n_hidden).to(device)\n",
    "C_net = C(n_dim, n_ch, d_feature_map_b, n_class, n_continue, n_hidden).to(device)\n",
    "opt_C = optim.Adam(C_net.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "opt_G = optim.Adam(G_net.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "opt_Q = optim.Adam(itertools.chain(C_net.parameters(), G_net.parameters()), lr=0.0002, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f32cbcbd51c47a8859ddac5a654c36c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200/5000] G: -1.2312, D:-0.2658, Q:1.1722 -- elapsed_G: 0.0086s -- elapsed_D: 0.0777s\n",
      "[400/5000] G: 1.3551, D:-0.9838, Q:1.1623 -- elapsed_G: 0.0086s -- elapsed_D: 0.0783s\n",
      "[600/5000] G: -0.6183, D:-0.8365, Q:1.1693 -- elapsed_G: 0.0087s -- elapsed_D: 0.0780s\n",
      "[800/5000] G: 1.2733, D:-1.1359, Q:1.1671 -- elapsed_G: 0.0087s -- elapsed_D: 0.0787s\n",
      "[1000/5000] G: -0.2518, D:-0.5022, Q:1.1724 -- elapsed_G: 0.0088s -- elapsed_D: 0.0778s\n",
      "[1200/5000] G: -4.2487, D:-0.4045, Q:1.1580 -- elapsed_G: 0.0087s -- elapsed_D: 0.0816s\n",
      "[1400/5000] G: -1.1337, D:-0.6816, Q:1.1698 -- elapsed_G: 0.0087s -- elapsed_D: 0.0795s\n",
      "[1600/5000] G: -0.1219, D:-0.6804, Q:1.1613 -- elapsed_G: 0.0087s -- elapsed_D: 0.0787s\n",
      "[1800/5000] G: -0.1863, D:-0.1880, Q:1.1706 -- elapsed_G: 0.0087s -- elapsed_D: 0.0782s\n",
      "[2000/5000] G: 0.2671, D:0.7488, Q:1.1704 -- elapsed_G: 0.0087s -- elapsed_D: 0.0789s\n",
      "[2200/5000] G: -1.2408, D:-0.4046, Q:1.1681 -- elapsed_G: 0.0088s -- elapsed_D: 0.0792s\n",
      "[2400/5000] G: 0.1058, D:-0.9258, Q:1.1685 -- elapsed_G: 0.0087s -- elapsed_D: 0.0786s\n",
      "[2600/5000] G: -0.1418, D:-0.0068, Q:1.1659 -- elapsed_G: 0.0087s -- elapsed_D: 0.0806s\n",
      "[2800/5000] G: -0.3636, D:-0.1765, Q:1.1662 -- elapsed_G: 0.0087s -- elapsed_D: 0.0787s\n",
      "[3000/5000] G: -0.5868, D:-0.1090, Q:1.1710 -- elapsed_G: 0.0088s -- elapsed_D: 0.0802s\n",
      "[3200/5000] G: -1.7553, D:-0.3677, Q:1.1683 -- elapsed_G: 0.0087s -- elapsed_D: 0.0788s\n",
      "[3400/5000] G: -0.1652, D:-0.3333, Q:1.1636 -- elapsed_G: 0.0088s -- elapsed_D: 0.0789s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c9e9b3c3e2d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0md_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_loss_real\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0md_loss_fake\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0md_gp_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mopt_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0md_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;31m# train Q:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "\n",
    "iterations = 5000\n",
    "preview_iter = 200\n",
    "preview_imgs = 8\n",
    "std = 1.0\n",
    "lambda_1 , lambda_2 = 10 , 0.2\n",
    "M = 0.05\n",
    "k, p = 2, 6\n",
    "\n",
    "samples_preview = []\n",
    "labels_preview = []\n",
    "conts_preview = []\n",
    "for c in range(n_class):\n",
    "    samples_preview.append(torch.randn(preview_imgs, n_feature).clamp(-3,3) * std)\n",
    "    labels_preview.append(one_hot(torch.LongTensor([c]*preview_imgs, device=\"cpu\"), n_class))\n",
    "    conts_preview.append(torch.rand(preview_imgs, n_continue) * 2 - 1)\n",
    "\n",
    "for ite in tqdm_notebook(range(1, iterations+1)):\n",
    "    start_train_ts = time.time()\n",
    "    \n",
    "    # train G:\n",
    "    G_net.train()\n",
    "    C_net.train() # activate Discriminator's Dropout \n",
    "    opt_G.zero_grad()\n",
    "    label = torch.randint(n_class, (batch_size,))\n",
    "    label_ohe = one_hot(label, n_class).to(device)\n",
    "    label = label.to(device)\n",
    "    cnt = torch.rand(batch_size, n_continue) * 2 - 1\n",
    "    cnt = cnt.to(device)\n",
    "    sample = torch.randn(batch_size, n_feature, device=device).clamp(-3,3) * std\n",
    "    generated = G_net(sample, label_ohe, cnt)\n",
    "    g_loss = C_net(generated)[0].mean()\n",
    "    g_loss.backward()\n",
    "    opt_G.step()\n",
    "    g_loss = g_loss.item()\n",
    "    G_update_ts = time.time()\n",
    "    \n",
    "    # train D:\n",
    "    G_net.eval()\n",
    "    C_net.train()\n",
    "    opt_C.zero_grad()\n",
    "    real = next(gen)\n",
    "    real = real.to(device)\n",
    "    label = torch.randint(n_class, (real.size(0),))\n",
    "    label_ohe = one_hot(label, n_class).to(device)\n",
    "    label = label.to(device)\n",
    "    cnt = torch.rand(real.size(0), n_continue) * 2 - 1\n",
    "    cnt = cnt.to(device)\n",
    "    sample = torch.randn(real.size(0), n_feature, device=device).clamp(-3,3) * std\n",
    "    with torch.no_grad():\n",
    "        fake   = G_net(sample,label_ohe,cnt).detach() # not to touch G_net\n",
    "    fake.requires_grad_(True)\n",
    "    real.requires_grad_(True)\n",
    "    d_real = C_net(real)[0]\n",
    "    d_fake = C_net(fake)[0]\n",
    "    d_loss_real = d_real.mean()\n",
    "    d_loss_real.backward(retain_graph=True)\n",
    "    d_loss_fake = -d_fake.mean()\n",
    "    d_loss_fake.backward(retain_graph=True)\n",
    "    d_real_gp = wgan_div_gp(real, d_real, device, p)\n",
    "    d_fake_gp = wgan_div_gp(fake, d_fake, device, p)\n",
    "    d_gp_loss = (d_real_gp+d_fake_gp).mean() * k / 2\n",
    "    d_gp_loss.backward(retain_graph=True)\n",
    "    d_loss = d_loss_real + d_loss_fake + d_gp_loss\n",
    "    opt_C.step()\n",
    "    d_loss = d_loss.item()\n",
    "    \n",
    "    # train Q:\n",
    "    G_net.eval()\n",
    "    C_net.train()\n",
    "    opt_Q.zero_grad()\n",
    "    label = torch.randint(n_class, (batch_size,))\n",
    "    label_ohe = one_hot(label, n_class).to(device)\n",
    "    label = label.to(device)\n",
    "    cnt = torch.rand(batch_size, n_continue) * 2 - 1\n",
    "    cnt = cnt.to(device)\n",
    "    sample = torch.randn(batch_size, n_feature, device=device).clamp(-3,3) * std\n",
    "    fake   = G_net(sample,label_ohe,cnt)\n",
    "    p_class, p_cnt = C_net(fake)[1:]\n",
    "    class_loss = F.nll_loss(p_class, label, reduction='mean')\n",
    "    cnt_loss = F.mse_loss(p_cnt, cnt, reduction='mean')\n",
    "    q_loss = 0.5*class_loss + 0.05 * cnt_loss\n",
    "    q_loss.backward()\n",
    "    opt_Q.step()\n",
    "    q_loss = q_loss.item()\n",
    "    D_update_ts = time.time()\n",
    "    \n",
    "    if ite%preview_iter==0:\n",
    "        print('[{}/{}] G: {:.4f}, D:{:.4f}, Q:{:.4f} -- elapsed_G: {:.4f}s -- elapsed_D: {:.4f}s'.format(ite, iterations, g_loss, d_loss, q_loss, (G_update_ts-start_train_ts), (D_update_ts-G_update_ts) ))\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            G_net.eval() # evaluation state\n",
    "            imgs = []\n",
    "            for sample, label, cnt in zip(samples_preview, labels_preview, conts_preview):\n",
    "                generated = G_net(sample.to(device), label.to(device), cnt.to(device)).detach().cpu().numpy()\n",
    "                imgs.append(np.concatenate(generated, axis=2))\n",
    "            imgs = np.asarray(imgs)\n",
    "        \n",
    "        plot2dir('./previews', imgs, ite)\n",
    "        torch.save(G_net.state_dict(), './checkpoints/iter-{:d}-G.ckpt'.format(ite))\n",
    "        torch.save(C_net.state_dict(), './checkpoints/iter-{:d}-D.ckpt'.format(ite))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
